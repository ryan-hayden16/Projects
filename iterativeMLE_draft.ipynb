{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "iterativeMLE_draft.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPxmdhcuYjbLcoIUtZlrSWH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ryan-hayden16/Projects/blob/main/iterativeMLE_draft.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Preliminary steps"
      ],
      "metadata": {
        "id": "ACb79dw-HJBI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# imports and installs\n",
        "!pip install scanpy # tools for scRNA-seq analysis\n",
        "!pip install matplotlib==3.1.3 # current version produces error w/ scanpy\n",
        "!pip install sklearn # tools for general data analysis\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import scanpy as sc\n",
        "import sklearn\n",
        "import matplotlib.pyplot as plt\n",
        "import math\n",
        "from sklearn import metrics\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "!pip install matplotlib==3.1.3 # reinstall to force old package version"
      ],
      "metadata": {
        "id": "T5mtH5zxGoPv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load data (and metadata, if available)"
      ],
      "metadata": {
        "id": "iTTW7u9ajXjl"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5uTVsT3SBzgq"
      },
      "outputs": [],
      "source": [
        "# load data matrix (single patient/sample)\n",
        "x = pd.read_csv(\"/content/Kidney-counts.csv\", index_col=0)\n",
        "x = np.transpose(x) # transpose into cell by gene format"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# load metadata (if available, can be used to check cluster accuracy)\n",
        "metadata = pd.read_csv(\"/content/annotations_FACS.csv\", index_col=0)\n",
        "metadata = metadata.loc[metadata['tissue'].isin(['Kidney'])]"
      ],
      "metadata": {
        "id": "6z6KfDLIGdjJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# remove raw data with missing labels\n",
        "cellclass=metadata.cell_ontology_class\n",
        "cellclass=cellclass.to_frame()\n",
        "mergedf=x.merge(cellclass, left_index=True, right_index=True)\n",
        "metadf=mergedf.cell_ontology_class\n",
        "metadf=metadf.to_frame()\n",
        "bladf=mergedf.drop(columns=['cell_ontology_class'])\n",
        "\n",
        "# now raw data and metadata have matching sizes\n",
        "x=bladf\n",
        "x_labels=metadf\n",
        "\n",
        "# create annotated data matrix (ie: anndata) to use with scanpy\n",
        "adata_raw = sc.AnnData(X = x, obs = x_labels)"
      ],
      "metadata": {
        "id": "-wCkOuJ8KAN-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "46bfddee-c863-493d-f644-794962f57e85"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:14: FutureWarning: X.dtype being converted to np.float32 from int64. In the next version of anndata (0.9) conversion will not be automatic. Pass dtype explicitly to avoid this warning. Pass `AnnData(X, dtype=X.dtype, ...)` to get the future behavour.\n",
            "  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Quality control of raw data (optional)"
      ],
      "metadata": {
        "id": "loEAml3ujeA2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# quality control of raw data? (need old matplotlib version to avoid errors)\n",
        "\n",
        "# quality control\n",
        "adata_qc=adata_raw # keep copy of the raw data\n",
        "is_spike_in = {}\n",
        "for gene_name in adata_qc.var_names:\n",
        "    if 'ERCC' in gene_name:\n",
        "        is_spike_in[gene_name] = True # record that we found a spike-in\n",
        "    else:\n",
        "        is_spike_in[gene_name] = False # record that this was not a spike-in\n",
        "adata_qc.var['ERCC'] = pd.Series(is_spike_in) # label the spike ins\n",
        "qc = sc.pp.calculate_qc_metrics(adata_qc, qc_vars = ['ERCC']) # scanpy function\n",
        "cell_qc_dataframe = qc[0] # cell quality control\n",
        "gene_qc_dataframe = qc[1] # gene quality control\n",
        "\n",
        "# cell filtering and gene filtering\n",
        "low_ERCC_mask = (cell_qc_dataframe['pct_counts_ERCC'] < 10)\n",
        "adata_qc = adata_qc[low_ERCC_mask]\n",
        "sc.pp.filter_cells(adata_qc, min_genes = 750) # filter cells \n",
        "sc.pp.filter_genes(adata_qc, min_cells = 2) # filter genes\n",
        "sc.pp.filter_genes(adata_qc, min_counts = 10)\n",
        "\n",
        "#run PCA with no labels\n",
        "sc.pp.pca(adata_qc)\n",
        "sc.pl.pca_overview(adata_qc) # plot\n",
        "\n",
        "# run PCA as exploratory measure to check the data out\n",
        "sc.pp.pca(adata_qc)\n",
        "sc.pl.pca_overview(adata_qc, color='cell_ontology_class') # plot\n",
        "\n",
        "# normalize the data \n",
        "adata_norm=adata_qc # keep copy of qc data\n",
        "sc.pp.normalize_per_cell(adata_norm, counts_per_cell_after=1e6)\n",
        "sc.pp.normalize_total(adata_norm, target_sum=1e6, exclude_highly_expressed=True)\n",
        "\n",
        "# (OPTIONAL) Remove highly expressed genes distorting the data\n",
        "not_Rn45s = adata_norm.var.index != 'Rn45s'\n",
        "adata_no_Rn45s = adata_norm[:, not_Rn45s] # keep copy of normed data\n",
        "# need to check which genes to remove\n",
        "\n",
        "# scale the data\n",
        "adata_scale=adata_no_Rn45s\n",
        "# adata_scale=adata_norm\n",
        "sc.pp.log1p(adata_scale)\n",
        "sc.pp.scale(adata_scale)\n",
        "\n",
        "#re-run PCA with no labels\n",
        "sc.pp.pca(adata_scale)\n",
        "sc.pl.pca_overview(adata_scale) # plot\n",
        "\n",
        "# re-run PCA, should seperate data better this time\n",
        "sc.pp.pca(adata_scale)\n",
        "sc.pl.pca_overview(adata_scale, color='cell_ontology_class') # plot\n",
        "\n",
        "adata=adata_scale # adata is now quality controlled, normalized, and scaled"
      ],
      "metadata": {
        "id": "fq_NGXbEOMJR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Extract count matrix from raw data"
      ],
      "metadata": {
        "id": "EcPf1JCnjp82"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# convert data matrix in adata to dataframe\n",
        "x = pd.DataFrame(adata.X)\n",
        "x=x.set_index(adata.obs.index)\n",
        "\n",
        "#NOTE, numpy ndarray is preferable to dataframe because it can be more than 2 dimensions, but tensorflow tensor might be computationally advantageous"
      ],
      "metadata": {
        "id": "irKCY-vZQDr5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Define known variables"
      ],
      "metadata": {
        "id": "490RutdYSQMf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# define known values\n",
        "C,G = x.shape # retrieve number of cells and genes from raw data matrix\n",
        "K = 5 # predicted number of cell-types\n",
        "L = 3 # predicted number of gene-communities (ie: high, medium, low expression communities)\n",
        "\n",
        "\n",
        "# define distribution f (start with Poisson) \n",
        "poisson pdf"
      ],
      "metadata": {
        "id": "Bt2cKQqeSX7j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "python notes"
      ],
      "metadata": {
        "id": "iDlpmkIqcgui"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#create tensor in python\n",
        "import random\n",
        "C=50\n",
        "G=100\n",
        "K=5 \n",
        "L=3 \n",
        "Q=np.zeros((G,K,L))\n",
        "for i in range(G):\n",
        "  for j in range(K):\n",
        "    for l in range(L):\n",
        "      Q[i,j,l]=random.uniform(0, 1)\n",
        "\n",
        "print(Q)\n",
        "# Q is GxKxL tensor"
      ],
      "metadata": {
        "id": "q_6V-Mn4npNd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# generate fake (normalized) count data\n",
        "X=np.zeros((C,G))\n",
        "for c in range(C):\n",
        "  for g in range(G):\n",
        "    X[c,g]=random.uniform(0,1)"
      ],
      "metadata": {
        "id": "pdFMKUiFsDJ9"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4jfYkLZa_ukp",
        "outputId": "b9cb98a7-cc8d-4b73-cc94-0866c739f65d"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.6753744 , 0.8320612 , 0.49918573, ..., 0.35695974, 0.01775405,\n",
              "        0.60654286],\n",
              "       [0.78257583, 0.87906851, 0.97402181, ..., 0.26331163, 0.24914387,\n",
              "        0.41427641],\n",
              "       [0.66946349, 0.99919073, 0.54409948, ..., 0.39638758, 0.71148458,\n",
              "        0.47074642],\n",
              "       ...,\n",
              "       [0.11847296, 0.96767791, 0.78908677, ..., 0.9368653 , 0.61783446,\n",
              "        0.02920085],\n",
              "       [0.25210393, 0.83065315, 0.8495982 , ..., 0.90617789, 0.21553334,\n",
              "        0.80976785],\n",
              "       [0.6560573 , 0.24328608, 0.22514646, ..., 0.50866792, 0.95877456,\n",
              "        0.70112941]])"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Initialize S and T variables"
      ],
      "metadata": {
        "id": "dhO_yZPhkG5h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# initialize S\n",
        "import scipy as sp\n",
        "from numpy import linalg as LA\n",
        "from scipy.linalg import sqrtm\n",
        "from numpy.linalg import inv\n",
        "from sklearn.preprocessing import normalize\n",
        "from sklearn.cluster import KMeans\n",
        "\n",
        "\n",
        "A=np.dot(X,np.transpose(X)) #step 1 (affinity matrix, simple version)\n",
        "\n",
        "D=np.zeros((C,C))\n",
        "for i in range(C):\n",
        "  D[i,i] = sum(A[i,:]) #step 2.a (graph laplacian)\n",
        "\n",
        "E=sqrtm(D) \n",
        "F=inv(E) \n",
        "H=np.dot(F,np.dot(A,F)) #step 2.b (graph laplacian)\n",
        "\n",
        "\n",
        "w, v = LA.eig(H) #step 3 (find K largest (orthogonal) eigenvectors of H and form a CxK matrix with them) and normalize the matrix\n",
        "ordered_eigval=np.argsort(w) # returns indexes of ordered (small to large) of w (eigenvalue list)\n",
        "k_large_eigval = ordered_eigval[-K:] # returns indexes of K largest eigvals\n",
        "k_large_eigvec=np.transpose(v[k_large_eigval]) # returns corresponding K largest eigvecs, as a CxK ndarray\n",
        "Y = normalize(k_large_eigvec, axis=1, norm='l2') #normalize rows of the CxK matrix\n",
        "\n",
        "\n",
        "#step 5 (treat each of the C rows of the matrix as a K-dim vector and cluster into K-clusters, via K-means)\n",
        "kmeans = KMeans(n_clusters=K, random_state=0).fit(Y)\n",
        "cluster_labels = kmeans.labels_\n",
        "\n",
        "#step 6 (assign/label each of the C cells into the corresponding cluster (ie: labels are 1,2,...,K) from step 5)\n",
        "S=np.zeros((C,K))\n",
        "for i in range(C):\n",
        "  for j in range(K):\n",
        "    if cluster_labels[i]==j:\n",
        "      S[i,j]=1\n",
        "#(each cell now has a label from 1,...,K, so we can then form the CxK classification matrix (ie: matrix S) that we want)\n",
        "\n",
        "\n",
        "# this process gives us S_0\n",
        "\n",
        "# THIS CODE IS FINISHED AND HAS BEEN CHECKED TO BE WORKING PROPERLY"
      ],
      "metadata": {
        "id": "FyVuZx30S9o1"
      },
      "execution_count": 133,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "S.shape"
      ],
      "metadata": {
        "id": "MPFYPxqqatj-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "S"
      ],
      "metadata": {
        "id": "Rj08gDs8bLpg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cluster_labels # compare with S printout above to see that it worked"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y5q1R9CGTNP_",
        "outputId": "bc5eccf4-7368-4a97-98ff-d8041dc6d92b"
      },
      "execution_count": 138,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([3, 2, 4, 3, 0, 2, 3, 4, 1, 4, 2, 4, 3, 3, 2, 2, 2, 0, 1, 1, 3, 4,\n",
              "       2, 4, 1, 0, 1, 1, 3, 2, 2, 3, 4, 1, 1, 0, 2, 3, 1, 3, 3, 2, 2, 0,\n",
              "       0, 4, 0, 2, 0, 3], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 138
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# initialize T\n",
        "\n",
        "#step 0 (using 1,...,K labels from above, turn X matrix into K submatrices, where each submatrix X_1,...,X_K corresponds to a label, and note each has G columns but varying number of columns)\n",
        "CREATE K EMPTY ARRAYS, AND LOOP THROUGH CLUSTER_LABELS AND APPEND EACH ROW VECTOR FROM X TO THE X_i MATRIX ITS LABEL CORRESPONDS TO\n",
        "LABEL THESE MATRIXES X_1,...,X_K AND LOOP THROUGH 1 TO K, EACH TIME PERFORMING THE BELOW STEPS\n",
        "\n",
        "#step 1 (form K affinity matrices A_1,..., A_K, where A_i = (X_i^transpose)*X_i is a GxG matrix)\n",
        "BESIDES KEEPING TRACK OF X_i VS X_j SHOULD BE ABLE TO JUST COPY ABOVE CODE, \n",
        "BUT ALSO MAKE SURE TO SWAP TRANSPOSE ORDER SO ITS NOW GxG AFFINITY MATRIX, AND SWAP WHEREVER ELSE NECCESARY, IE NOW K-MEANS ON COLUMNS AND NORMALIZE COLUMNS, ETC...\n",
        "THE FINAL RESULT SHOULD BE K SEPERATE GxL CLASSIFICATION MATRICES, YIELDING THE DESIRED GxKxL TENSOR\n",
        "\n",
        "#now repeat steps 2-7 from above (but now using L clusters/eigenvectors), to obtain K seperate GxL classification matrices, this gives us the GxKxL classification tensor that we want\n",
        "\n",
        "\n",
        "# this process gives us T_0"
      ],
      "metadata": {
        "id": "x6bGjFp6xepy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Initialize theta paramaters"
      ],
      "metadata": {
        "id": "-AO8mGGOcwDk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# using S_0 and T_0 and X, we can directly calculate rho_0, pi_0, and mu_0\n",
        "\n",
        "rho: use yunpeng line (12) and S_0\n",
        "pi: use yunpeng line (13) and T_0\n",
        "mu: use yunpeng line (14) and S_0, T_0, X "
      ],
      "metadata": {
        "id": "50X4L91Ucyk7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Iterative maximization scheme"
      ],
      "metadata": {
        "id": "ITNRNSiPcdH8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# start with S_0, T_0, rho_0, pi_0, mu_0\n",
        "\n",
        "# loop through steps 1 and 2\n",
        "\n",
        "\n",
        "#NOTE: be careful with regard to dropouts/blowups, use appropriate numerical techniques\n",
        "\n",
        "\n",
        "# step 1: update S, rho, mu\n",
        "fix previous values of S, T, rho, pi, mu \n",
        "calculate updated S # E step (define function) \n",
        "USE YUNPENG LINE (9)\n",
        "calculate updated rho, mu # M step (define function)\n",
        "USE YUNPENG LINES (12 & 14)\n",
        "\n",
        "# step 2: update T, pi, mu\n",
        "fix previous values of S, T, rho, pi, mu \n",
        "calculate updated T # E step (define function)\n",
        "USE YUNPENG LINE (10)\n",
        "calculate updated pi, mu # M step (define function)\n",
        "USE YUNPENG LINES (13 & 14)\n",
        "\n",
        "# stop loop if convergence criteria met, ie: S and T both no longer changing values to significant degree\n",
        "IE: T_(M+1)-T_(M) < epsilon, and similar for S_(M)"
      ],
      "metadata": {
        "id": "x0NqfJYfZ2AN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "cXlixFjkVwiO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# convert S and T into labels Z and W\n",
        "# check Z (cell-type) labels against true labels from metadata\n",
        "# check high expression gene-community against known biomarkers for associated cell-type"
      ],
      "metadata": {
        "id": "JHWsWooVaiIm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# figure out way to visualize Z and W labels"
      ],
      "metadata": {
        "id": "X_Z26Zcqa5fl"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}